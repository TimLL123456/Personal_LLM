{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "sD1Qn9NqrB0G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class deepseek:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.client = OpenAI(api_key=userdata.get(\"deepseek_api\"),\n",
        "                             base_url=\"https://api.deepseek.com/v1\")\n",
        "\n",
        "        self.message_history = []\n",
        "\n",
        "    def simple_chat_generate(self, query):\n",
        "\n",
        "        messages = {\"role\":\"user\", \"content\":query}\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"deepseek-chat\",\n",
        "            messages=[messages]\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content\n",
        "\n",
        "        self.message_history.append(messages)\n",
        "        self.message_history.append({\"role\":\"assistant\", \"content\":content})\n",
        "\n",
        "        return content\n",
        "\n",
        "    def chat_generate(self, query, model=\"deepseek-chat\", stream=True):\n",
        "\n",
        "        messages = {\"role\":\"user\", \"content\":query}\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[messages],\n",
        "            stream=stream\n",
        "        )\n",
        "\n",
        "        if stream:\n",
        "            reasoning_content = \"\"\n",
        "            content = \"\"\n",
        "\n",
        "            for chunk in response:\n",
        "                if model == \"deepseek-reasoner\":\n",
        "                    reasoning_content += chunk.choices[0].delta.reasoning_content\n",
        "                    content += chunk.choices[0].delta.content\n",
        "                else:\n",
        "                    content += chunk.choices[0].delta.content\n",
        "\n",
        "            print(f\"<think>\\n{reasoning_content}</think>\\n\\n{content}\")\n",
        "\n",
        "        else:\n",
        "            content = \"\"\n",
        "            content = response.choices[0].message.content\n",
        "            print(content)\n",
        "\n",
        "        self.message_history.append(messages)\n",
        "        self.message_history.append({\"role\":\"user\", \"content\":content})"
      ],
      "metadata": {
        "id": "WNE6hW1RbHtW"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = deepseek()"
      ],
      "metadata": {
        "id": "3xrPdknBztJj"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.simple_chat_generate(\"who are you\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC79jM-5eTTv",
        "outputId": "84c83d22-7a1b-458e-aaae-38a7f4cfc5d7"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am an AI language model created by OpenAI, designed to assist with answering questions, providing information, generating text, and helping with various tasks. You can think of me as a virtual assistant that uses natural language processing to understand and respond to your queries. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dp_model = \"deepseek-reasoner\"\n",
        "model.chat_generate(\"introduce hong kong to me in short\", model=dp_model, stream=True)"
      ],
      "metadata": {
        "id": "_WpRLXJVzDVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
